## About

***DeepCompressor*** is an open source model compression toolbox for large language models and diffusion models based on PyTorch. DeepCompressor currently supports fake quantization with any integer and floating-point data type within 8 bits, e.g., INT8, INT4 and FP4_E2M1.

This repository forks from the original Deepcompressor repository - https://github.com/mit-han-lab/deepcompressor?tab=readme-ov-file

  + Model checkpoints for the quantized model can be found here - https://drive.google.com/drive/folders/1XEaOjAr0kg9OnXKwKYfjiCGuFHOsEXsU?dmr=1&ec=wgc-drive-hero-goto
  + The colab file used to run commands to generate the results in the above folders can be found here - https://colab.research.google.com/drive/1N8E_M9gZ8x5lQWwGRp9PYUsLIatfHs_8#scrollTo=j1qvvGgWt6-Q
  + The folders benchmarks and baselines contains comparison statistics and sample images generated.